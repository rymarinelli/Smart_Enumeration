{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ4Zg__fmsOx",
        "outputId": "fa1dcba0-9f4d-4a0a-d072-aa2be5dfdf72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "! pip install stable_baselines3 gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95b65477c50a41b3a2cb5e8d51a016a6",
            "c4c5d7d0dba94012be667da8701c2de8",
            "648d9e8d4a1746ffa4c0ffe41a5c027d",
            "9a2636b0a6ff4a9482d2f4f14ba8264f",
            "99cb13ff8f1641b28136da8c77cb2278",
            "bd25875f96e54e78b04875916c549750",
            "9276915575694cfcb7e1dc305af2870b",
            "c3d046f3ba6d4583814f94c3916780ac",
            "da34d77d223a41b8860c08d8e12c0cc1",
            "efd5d7f82ddc4787b01743de6012706d",
            "40e93398749e40a0933dea004a3adefb",
            "db6272fb65c5491fbdccf5230d73d41c",
            "fce36bf4ac794945896e8e61db0faf17",
            "82b4eac9929043b281c7e75956f48cc2",
            "f4f0742357f94dc58bf3c9b8ce2f4317",
            "77f25e70933145249eaeb883ce72eda5",
            "dd9fd68df8e548c78b9b615b306838c3",
            "0fa21a607057496aa1e003aca91cfeaa",
            "6b594ed8f0734b0c80db1ebe13a246b1",
            "2db6b90f28d546cd8cdfe19f1c523e99",
            "5e5909caf5fa4f9694ee3010536b07b0",
            "f67eb7f84a6e4ad0b84e51897a6e42a9",
            "83cbdd87e4884afea3a796db37992afd",
            "88a9d60d0a464b599d6d899419b0b191",
            "08dd42a1e7eb4c3990fb02c8e3347201",
            "3af35e028f4f49a987fe9357f8410928",
            "48a60584e9834015b6da031d1e0e1d12",
            "447cae765b9944fc9414bc76bc5ce626",
            "c06130eeb0c94082890e990e50b5a675",
            "84869fb0f5434bc0a5485211496c3443",
            "d8363b01a9c34050b77b7cffbb8b617b",
            "6cb1ec65ea9045d1b107fae6dcf353ec",
            "8975871f24aa464c89121ed0e1063c0e",
            "56bed4db5b804f16a4c9d4d436bdef2b",
            "3749ccc419414b45ada5f78dc7a4372f",
            "c1ed529dcfbd4722a92cc1ae061e009d",
            "f059d92712dd4756a123363d09a36fa9",
            "4ea6371e6f1342cf967dc2beefb27648",
            "8dbf4a012e894611a590f9bdea7bc6ba",
            "3d46b9776e77497aabe14382f1a6e679",
            "00b0b44b22eb4749b02becd426c1366e",
            "d3c237626d4a46b88cc727da6752d599",
            "4ce4e3d433f7470c9918c6fb8673368a",
            "2dd75fd423734d6bb8a965e7f5fa5c88",
            "03899a2a6c9f4c8c8fce5e9cfde497e1",
            "51858f12223f49bf936e4f725c9c63dc",
            "60964037da4f4ddea642d8d88a76f86b",
            "4d2eb65931af4b798d3b1fd31a86ece0",
            "15f5f3be69f9426ea7a102fd17e19caf",
            "03d9c59daa9745c1928fcbdc846eea5e",
            "54f46d83d7da4b55a7b4f313be81544c",
            "15ff000889da4787bb3270aa4fed8b47",
            "318724dcd7ec43668e6ee8040de18a02",
            "6d29fac184a94ddb8f71ec7ed02e8c2e",
            "99a865732adf49078d89dba418158cd2"
          ]
        },
        "id": "QTZGIFz1BxBG",
        "outputId": "3ac8696d-a199-455b-a034-6e54a7e34759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2024.12.14)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.37.2\n",
            "Collecting flash_attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash_attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn) (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash_attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash_attn) (3.0.2)\n",
            "Building wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: flash_attn\n",
            "Successfully installed flash_attn-2.7.4.post1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95b65477c50a41b3a2cb5e8d51a016a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db6272fb65c5491fbdccf5230d73d41c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83cbdd87e4884afea3a796db37992afd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56bed4db5b804f16a4c9d4d436bdef2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03899a2a6c9f4c8c8fce5e9cfde497e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install transformers==4.37.2\n",
        "!pip install flash_attn\n",
        "\n",
        "import logging\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "# Load tokenizer and model\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    language_model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.bfloat16\n",
        "    ).cuda()\n",
        "    logging.info(\"Model and tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.exception(\"Failed to load the model and tokenizer.\")\n",
        "    exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwVbECYXJKCa",
        "outputId": "5454a2bd-6308-400f-da41-dfd6398bd3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting scrape from: http://3cpo.hackingarena.com:802/\n",
            "[*] Scraping: http://3cpo.hackingarena.com:802/\n",
            "[*] Scraping: http://3cpo.hackingarena.com:802/Levitation\n",
            "[*] Scraping: http://3cpo.hackingarena.com:802/Stunning\n",
            "[*] Scraping: http://3cpo.hackingarena.com:802/Boggart_Banishing\n",
            "[*] Scraping: http://3cpo.hackingarena.com:802/Mysterious_Note\n",
            "\n",
            "[+] Scraping complete!\n",
            "\n",
            "[+] Compiled Context Preview:\n",
            "\n",
            "Order of the Pheonix\n",
            "Welcome to the Order of the Pheonix\n",
            "We will practice many different challenges here. The correct spell has to be cast to complete each challenge.\n",
            "For example, the levitation challenge is found in: \"/Levitation\"\n",
            "To make an object levitate, use Wingardium Leviosa: \"/Levitation/Wingardium_Leviosa\"\n",
            "Levitation\n",
            "Stunning\n",
            "Boggart Banishing\n",
            "Mysterious Note\n",
            "\n",
            "PRE Tags:\n",
            "\n",
            "\n",
            "CODE Tags:\n",
            "\n",
            "Levitation\n",
            "What's the spell to make something levitate?\n",
            "Back to common room\n",
            "\n",
            "PRE Tags:\n",
            "\n",
            "\n",
            "CODE Tags:\n",
            "\n",
            "Stunning\n",
            "Use the stunning spell to stun your opponent!\n",
            "Back to common room\n",
            "\n",
            "PRE Tags:\n",
            "\n",
            "\n",
            "CODE Tags:\n",
            "\n",
            "Boggart Banishing\n",
            "You need a spell to banish the Boggart\n",
            "Back to common room\n",
            "\n",
            "PRE Tags:\n",
            "\n",
            "\n",
            "CODE Tags:\n",
            "\n",
            "Mysterious_Note\n",
            "Ginny cast Reducto, destroying a mannequin. You noticed a note lying in the ashes:\n",
            "To find me, guess the correct spell. The only hint I'll give: it's a single word. If you were Hermione and knew all possible spells, this would be easy for you.\n",
            "Back to common room\n",
            "\n",
            "PRE Tags:\n",
            "\n",
            "\n",
            "CODE Tag\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "# Function to get all links and content from a page\n",
        "def scrape_website(base_url, visited=None):\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "\n",
        "    if base_url in visited:  # Avoid revisiting the same link\n",
        "        return \"\"\n",
        "\n",
        "    visited.add(base_url)\n",
        "    print(f\"[*] Scraping: {base_url}\")  # Log progress\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, timeout=5)\n",
        "        response.raise_for_status()  # Raise error for HTTP issues\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract visible text from the page\n",
        "        page_text = soup.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "        # Handle <pre> and <code> tags explicitly for special content\n",
        "        pre_tags = \"\\n\".join([pre.get_text(separator=\"\\n\", strip=True) for pre in soup.find_all('pre')])\n",
        "        code_tags = \"\\n\".join([code.get_text(separator=\"\\n\", strip=True) for code in soup.find_all('code')])\n",
        "\n",
        "        # Combine extracted content\n",
        "        full_content = f\"{page_text}\\n\\nPRE Tags:\\n{pre_tags}\\n\\nCODE Tags:\\n{code_tags}\"\n",
        "\n",
        "\n",
        "        links = [urljoin(base_url, a['href']) for a in soup.find_all('a', href=True)]\n",
        "\n",
        "        # Filter links to stay within the same domain\n",
        "        filtered_links = [link for link in links if link.startswith(base_url) and link not in visited]\n",
        "\n",
        "        # Recursively scrape all sub-links\n",
        "        for link in filtered_links:\n",
        "            full_content += \"\\n\" + scrape_website(link, visited)\n",
        "\n",
        "        return full_content\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Error scraping {base_url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def compile_website_context(start_url):\n",
        "    print(f\"Starting scrape from: {start_url}\")\n",
        "    all_content = scrape_website(start_url)\n",
        "    print(\"\\n[+] Scraping complete!\")\n",
        "    return all_content\n",
        "\n",
        "\n",
        "base_url = \"http://3cpo.hackingarena.com:802/\"\n",
        "\n",
        "\n",
        "compiled_context = compile_website_context(base_url)\n",
        "\n",
        "\n",
        "with open(\"compiled_context.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(compiled_context)\n",
        "\n",
        "# Print a snippet of the compiled context\n",
        "print(\"\\n[+] Compiled Context Preview:\\n\")\n",
        "print(compiled_context[:1000])  # Print the first 1000 characters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "c8knoAuwPC8m",
        "outputId": "ec3abb42-fa69-475a-9690-992849250aa9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'language_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ecfdf8bb25af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Generate reasoning from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0msearch_decision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_search_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Print the Chain-of-Thought reasoning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ecfdf8bb25af>\u001b[0m in \u001b[0;36mprompt_search_decision\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Generate reasoning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     outputs = language_model.generate(\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'language_model' is not defined"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "\n",
        "# Context simulating scraped content from URLs\n",
        "context = \"\"\"\n",
        "The following content has been scraped from various webpages:\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/\n",
        "Welcome to the Order of the Pheonix.\n",
        "We will practice many different challenges here. The correct action must be taken to complete each challenge.\n",
        "For example, the levitation challenge is found in: \"/Levitation\".\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Levitation\n",
        "How would one approach making something rise?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Stunning\n",
        "What might be an effective way to disarm an opponent quickly?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Boggart_Banishing\n",
        "How might one eliminate or neutralize a fear-inducing entity?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Mysterious_Note\n",
        "Ginny cast Reducto, destroying a mannequin. You noticed a note lying in the ashes:\n",
        "\"To find me, guess the correct action. The only hint I'll give: it's a single word. If you were well-versed in known methods, this would be easy for you.\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def prompt_search_decision(context):\n",
        "    prompt = f\"\"\"\n",
        "The following content was scraped from various webpages:\n",
        "\n",
        "{context}\n",
        "\n",
        "Your task:\n",
        "1. Analyze whether the provided information is sufficient to deduce the goal subdirectory.\n",
        "2. If the data is insufficient, decide whether searching the internet for more data would be helpful. If more information is needed return [SEARCH NEEDED].\n",
        "3. Provide a step-by-step reasoning process and clearly state whether an internet search is necessary.\n",
        "\n",
        "Avoid directly stating the specific domain or solution but focus on whether external knowledge might assist in solving the challenge.\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=True\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Generate reasoning\n",
        "    outputs = language_model.generate(\n",
        "        inputs.input_ids,\n",
        "        attention_mask=inputs.attention_mask,\n",
        "        max_length=3000,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "\n",
        "search_decision = prompt_search_decision(context)\n",
        "\n",
        "\n",
        "print(\"[+] Search Decision Reasoning:\\n\")\n",
        "print(search_decision)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mwNB_M8bbQLN",
        "outputId": "29d84c23-3064-4c29-d689-e4fa48a93128"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'search_query' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-96378af4098d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[!] Query not found in brackets. Full response: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mextract_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'search_query' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "def extract_query(response):\n",
        "    start_idx = response.find(\"**[\")\n",
        "    end_idx = response.find(\"]**\")\n",
        "    if start_idx != -1 and end_idx != -1:\n",
        "        return response[start_idx + 1:end_idx].strip()\n",
        "    else:\n",
        "        print(f\"[!] Query not found in brackets. Full response: {response}\")\n",
        "        return None\n",
        "query= ''.join(filter(str.isalpha,  extract_query(search_query)))\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def search_duckduckgo(query, max_results=5):\n",
        "    \"\"\"\n",
        "    Search DuckDuckGo with a given query and return the top results.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query.\n",
        "        max_results (int): Maximum number of results to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of result URLs.\n",
        "    \"\"\"\n",
        "    print(f\"[*] Searching DuckDuckGo for: {query}\")\n",
        "    url = \"https://html.duckduckgo.com/html/\"\n",
        "    params = {'q': query}\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, data=params, headers=headers, timeout=10)\n",
        "        response.raise_for_status()  # Ensure request was successful\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        results = [a['href'] for a in soup.select('a.result__a')[:max_results]]\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Error during search: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "results = search_duckduckgo(query)\n",
        "print(f\"Search Results for '{query}':\")\n",
        "for result in results:\n",
        "    print(f\"- {result}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxuOk4ipoCSD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYJacuSch5Cr"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16\n",
        ").cuda()\n",
        "\n",
        "# DuckDuckGo search function\n",
        "def search_duckduckgo(query, max_results=5):\n",
        "    url = \"https://html.duckduckgo.com/html/\"\n",
        "    params = {'q': query}\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, data=params, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        results = [a['href'] for a in soup.select('a.result__a')[:max_results]]\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Error during search: {e}\")\n",
        "        return []\n",
        "\n",
        "# Ask the model if it has enough information\n",
        "def ask_if_sufficient(context):\n",
        "    prompt = f\"\"\"\n",
        "The following context describes a series of challenges related to subdirectory enumeration:\n",
        "\n",
        "{context}\n",
        "\n",
        "Task:\n",
        "1. Analyze the context and determine if you have enough information to enumerate the correct subdirectories.\n",
        "2. If you do not have enough information, clearly state what additional information or resources are needed to proceed.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024, padding=True).to(\"cuda\")\n",
        "    outputs = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_length=50000, temperature=0.7, top_p=0.9, do_sample=True)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "# Ask the model to suggest a search query\n",
        "def suggest_search_query(context):\n",
        "    prompt = f\"\"\"\n",
        "The following context describes a series of challenges related to subdirectory enumeration:\n",
        "\n",
        "{context}\n",
        "\n",
        "Task:\n",
        "1. Suggest a specific search query to find additional information needed to enumerate the correct subdirectories.\n",
        "2. Enclose your suggested search query in [brackets] for easy identification.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024, padding=True).to(\"cuda\")\n",
        "    outputs = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_length=300, temperature=0.7, top_p=0.9, do_sample=True)\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    start_idx = response.find(\"[\")\n",
        "    end_idx = response.find(\"]\")\n",
        "    if start_idx != -1 and end_idx != -1:\n",
        "        return response[start_idx + 1:end_idx].strip()\n",
        "    else:\n",
        "        print(f\"[!] Query not found in brackets. Full response: {response}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def main():\n",
        "    context = \"\"\"\n",
        "The following content has been scraped from various webpages:\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/\n",
        "Welcome to the Order of the Pheonix.\n",
        "We will practice many different challenges here. The correct action must be taken to complete each challenge.\n",
        "For example, the levitation challenge is found in: \"/Levitation\".\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Levitation\n",
        "How would one approach making something rise?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Stunning\n",
        "What might be an effective way to disarm an opponent quickly?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Boggart_Banishing\n",
        "How might one eliminate or neutralize a fear-inducing entity?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Mysterious_Note\n",
        "Ginny cast Reducto, destroying a mannequin. You noticed a note lying in the ashes:\n",
        "\"To find me, guess the correct action. The only hint I'll give: it's a single word. If you were well-versed in known methods, this would be easy for you.\"\n",
        "\"\"\"\n",
        "\n",
        "    while True:\n",
        "        # Ask the model if it has enough information\n",
        "        response = ask_if_sufficient(context)\n",
        "        print(f\"[+] Model's Response:\\n{response}\")\n",
        "\n",
        "        if \"enough information\" in response.lower():\n",
        "            print(\"[+] The model believes it has enough information to proceed.\")\n",
        "            break\n",
        "\n",
        "        if \"additional information\" in response.lower() or \"need\" in response.lower():\n",
        "            # Ask the model for a search query\n",
        "            search_query = suggest_search_query(context)\n",
        "            if not search_query:\n",
        "                print(\"[!] No valid search query generated. Exiting.\")\n",
        "                break\n",
        "\n",
        "            print(f\"[+] Suggested Search Query: {search_query}\")\n",
        "\n",
        "            # Perform the search\n",
        "            search_results = search_duckduckgo(search_query)\n",
        "            if search_results:\n",
        "                print(f\"[+] Search Results:\\n{search_results}\")\n",
        "\n",
        "                # Read the search results back into the context\n",
        "                results_context = \"\\n\".join(f\"- {url}\" for url in search_results)\n",
        "                context += f\"\\n\\nSearch Results:\\n{results_context}\"\n",
        "            else:\n",
        "                print(\"[!] No search results found. Exiting.\")\n",
        "                break\n",
        "\n",
        "        # Check if the model now realizes it needs a list of Harry Potter spells\n",
        "        if \"Harry Potter spells\" in response or \"list of spells\" in response:\n",
        "            print(\"[+] The model has concluded that it needs a list of Harry Potter spells to enumerate subdirectories.\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5CPvKg6l8HD",
        "outputId": "398928b4-2848-4374-af1f-0d4f8b694bb7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 10   |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 196  |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import logging\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
        "\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", trust_remote_code=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=\"auto\"\n",
        "    ).cuda()\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    logging.info(\"Model and tokenizer loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Failed to load model or tokenizer: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Verify CUDA availability\n",
        "if torch.cuda.is_available():\n",
        "    logging.info(\"CUDA is available. Using GPU for inference.\")\n",
        "else:\n",
        "    logging.warning(\"CUDA is not available. Using CPU for inference.\")\n",
        "    model = model.to(\"cpu\")\n",
        "\n",
        "#  RL environment\n",
        "class SubdirectoryEnv(gym.Env):\n",
        "    def __init__(self, parameters, max_steps=5, env_id=0):\n",
        "        super(SubdirectoryEnv, self).__init__()\n",
        "        self.env_id = env_id\n",
        "        self.parameters = parameters\n",
        "        self.context = parameters[\"context\"]\n",
        "        self.keywords = parameters[\"keywords\"]\n",
        "        self.max_steps = max_steps\n",
        "        self.current_step = 0\n",
        "        self.state = self.context\n",
        "        self.done = False\n",
        "\n",
        "        # action and observation space\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(1024,), dtype=np.float32)\n",
        "\n",
        "        # Configure environment-specific logger\n",
        "        self.logger = logging.getLogger(f\"Env_{self.env_id}\")\n",
        "        handler = logging.FileHandler(f\"env_{self.env_id}.log\")\n",
        "        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')\n",
        "        handler.setFormatter(formatter)\n",
        "        self.logger.addHandler(handler)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        self.state = self.context\n",
        "        self.done = False\n",
        "        self.logger.info(\"Environment reset.\")\n",
        "        return self._encode_state(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done:\n",
        "            self.logger.warning(\"Episode has ended. Call reset() to start a new episode.\")\n",
        "            raise Exception(\"Episode has ended. Call reset() to start a new episode.\")\n",
        "\n",
        "        start_step = time.time()\n",
        "        self.current_step += 1\n",
        "        reward = 0\n",
        "\n",
        "        # **Log the current step and action**\n",
        "        action_meanings = {0: \"Generate Query\", 1: \"Use Domain Knowledge\", 2: \"Conclude\"}\n",
        "        action_taken = action_meanings.get(action, \"Invalid Action\")\n",
        "        self.logger.info(f\"Step {self.current_step}: Action Taken - {action_taken}\")\n",
        "\n",
        "        if action == 0:  # Generate query\n",
        "            query = self.generate_query()\n",
        "            if not query:\n",
        "                self.logger.warning(\"Generated query is empty.\")\n",
        "                query = \"default search query\"\n",
        "            search_results = self.search_duckduckgo(query)\n",
        "            if not search_results:\n",
        "                self.logger.warning(\"Search results are empty.\")\n",
        "            reward = self.evaluate_query(query, search_results)\n",
        "            self.state += f\"\\nSearch Results:\\n{search_results}\"\n",
        "            self.update_context_with_results(search_results)\n",
        "            # **Log search results**\n",
        "            self.logger.info(f\"Search Results: {search_results}\")\n",
        "\n",
        "        elif action == 1:  # Use domain knowledge\n",
        "            if any(keyword in self.state for keyword in self.keywords):\n",
        "                reward = 5  # Strong reward for recognizing relevance\n",
        "                self.logger.info(\"Used relevant domain knowledge.\")\n",
        "            else:\n",
        "                reward = -1  # Penalty for irrelevant domain knowledge\n",
        "                self.logger.info(\"Attempted to use irrelevant domain knowledge.\")\n",
        "\n",
        "        elif action == 2:  # Conclusion\n",
        "            if self.check_completion():\n",
        "                reward = 10  # Strong reward for successful enumeration\n",
        "                self.done = True\n",
        "                self.logger.info(\"Successfully concluded enumeration.\")\n",
        "            else:\n",
        "                reward = -5  # Penalty for incorrect conclusion\n",
        "                self.logger.info(\"Incorrect conclusion attempted.\")\n",
        "\n",
        "        else:\n",
        "            reward = -1  # Invalid action\n",
        "            self.logger.warning(\"Invalid action attempted.\")\n",
        "\n",
        "        self.done = self.done or (self.current_step >= self.max_steps)\n",
        "        terminated = self.done\n",
        "        truncated = False\n",
        "\n",
        "        step_duration = time.time() - start_step\n",
        "        self.logger.info(f\"Step Duration: {step_duration:.2f} seconds.\")\n",
        "\n",
        "        # **Log the current state**\n",
        "        self.logger.debug(f\"Current State: {self.state}\")\n",
        "\n",
        "        return self._encode_state(), reward, terminated, truncated, {}\n",
        "\n",
        "    def _encode_state(self):\n",
        "        encoded = np.zeros(1024, dtype=np.float32)\n",
        "        state_bytes = np.frombuffer(self.state.encode(\"utf-8\"), dtype=np.uint8)[:1024]\n",
        "        encoded[:len(state_bytes)] = state_bytes / 255.0\n",
        "        return encoded\n",
        "\n",
        "    def generate_query(self):\n",
        "        try:\n",
        "            self.logger.debug(\"Entering generate_query method.\")\n",
        "            prompt = f\"Suggest a search query based on the following context:\\n{self.state}\"\n",
        "            inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024, padding=True).to(model.device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(\n",
        "                    inputs.input_ids,\n",
        "                    attention_mask=inputs.attention_mask,\n",
        "                    max_length=50,\n",
        "                    temperature=0.7,\n",
        "                    top_p=0.9,\n",
        "                    do_sample=True\n",
        "                )\n",
        "            query = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "            if not query:\n",
        "                self.logger.warning(\"Generated query is empty. Using default query.\")\n",
        "                query = \"default search query\"\n",
        "\n",
        "            # **Log the generated query**\n",
        "            self.logger.info(f\"Generated Query: '{query}'\")\n",
        "            self.logger.debug(\"Exiting generate_query method.\")\n",
        "            return query\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Exception in generate_query: {e}\")\n",
        "            return \"default search query\"\n",
        "\n",
        "    def search_duckduckgo(self, query, max_results=5):\n",
        "        url = \"https://html.duckduckgo.com/html/\"\n",
        "        params = {'q': query}\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, data=params, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            results = [a['href'] for a in soup.select('a.result__a')[:max_results]]\n",
        "            self.logger.info(f\"Actual Search Results: {results}\")\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error during search: {e}\")\n",
        "            return []\n",
        "\n",
        "\n",
        "    def evaluate_query(self, query, search_results):\n",
        "        if any(keyword.lower() in \" \".join(search_results).lower() for keyword in self.keywords):\n",
        "            return 3  # Reward for relevant query\n",
        "        return -1  # Penalty for irrelevant query\n",
        "\n",
        "    def check_completion(self):\n",
        "        return any(keyword in self.state for keyword in self.keywords)\n",
        "\n",
        "    def update_context_with_results(self, search_results):\n",
        "        additional_context = \"\\nAdditional Context from Search Results:\\n\" + \"\\n\".join(f\"- {result}\" for result in search_results)\n",
        "        self.state += additional_context\n",
        "\n",
        "# Wrap the environment for Stable-Baselines3\n",
        "class StableBaselinesEnv:\n",
        "    def __init__(self, parameters, n_envs=1):\n",
        "        self.env = SubprocVecEnv([lambda: SubdirectoryEnv(parameters, env_id=i) for i in range(n_envs)])\n",
        "\n",
        "    def train(self, total_timesteps=1):\n",
        "        model = PPO(\"MlpPolicy\", self.env, verbose=1)\n",
        "        model.learn(total_timesteps=total_timesteps)\n",
        "        return model\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    parameters = {\n",
        "        \"context\": \"The website provides challenges for 'Levitation', 'Stunning', 'Boggart Banishing', and a 'Mysterious Note'.\",\n",
        "        \"keywords\": [\"Harry Potter spells\", \"Levitation\", \"Stunning\", \"Boggart Banishing\"]\n",
        "    }\n",
        "\n",
        "    env = StableBaselinesEnv(parameters, n_envs=1)  # Set n_envs=1 for clearer logging\n",
        "    model = env.train(total_timesteps=1)  # Adjust timesteps as needed for testing\n",
        "\n",
        "    logging.info(\"[+] Training complete. The model is now optimized to recognize domain-specific knowledge.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTDi6KqhrpB3",
        "outputId": "16381bdb-eab8-4b06-cb27-1646778cef0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 10`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 10\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=10 and n_envs=1)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------\n",
            "| time/              |     |\n",
            "|    fps             | 0   |\n",
            "|    iterations      | 1   |\n",
            "|    time_elapsed    | 133 |\n",
            "|    total_timesteps | 10  |\n",
            "----------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# The known correct subdirectory (hidden \"goal\" for our agent)\n",
        "TARGET_SUBDIR = \"Dissendium\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1) Levenshtein Distance Function\n",
        "# ---------------------------------------------------------------------------\n",
        "def levenshtein_distance(s1, s2):\n",
        "    \"\"\"\n",
        "    Computes the Levenshtein (edit) distance between two strings, ignoring case.\n",
        "    \"\"\"\n",
        "    s1, s2 = s1.lower(), s2.lower()\n",
        "    if s1 == s2:\n",
        "        return 0\n",
        "    if not s1:\n",
        "        return len(s2)\n",
        "    if not s2:\n",
        "        return len(s1)\n",
        "\n",
        "    prev_row = list(range(len(s2) + 1))\n",
        "    for i, c1 in enumerate(s1):\n",
        "        curr_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            cost = 0 if c1 == c2 else 1\n",
        "            curr_row.append(min(\n",
        "                curr_row[-1] + 1,      # deletion\n",
        "                prev_row[j + 1] + 1,   # insertion\n",
        "                prev_row[j] + cost     # substitution\n",
        "            ))\n",
        "        prev_row = curr_row\n",
        "    return prev_row[-1]\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2) Environment Definition\n",
        "# ---------------------------------------------------------------------------\n",
        "class SubdirectoryEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Actions:\n",
        "      0. Generate Web Search Query (collect more context from DuckDuckGo)\n",
        "      1. Guess Subdirectory (HTTP GET to base_url/<guess>)\n",
        "      2. Use Domain Knowledge (reward if relevant keywords are in state)\n",
        "      3. Conclude (end the episode)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parameters, inference_fn, max_steps=12):\n",
        "        super().__init__()\n",
        "        self.parameters = parameters\n",
        "        self.base_url = parameters[\"base_url\"].rstrip(\"/\")\n",
        "        self.context = parameters[\"context\"]\n",
        "        self.keywords = parameters[\"keywords\"]\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.discovered = []\n",
        "\n",
        "        # The environment's text-based state starts with the given context\n",
        "        self.state = self.context\n",
        "\n",
        "        # 4 discrete actions\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        # Simple observation: a 1024-d float vector holding normalized text bytes\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(1024,), dtype=np.float32)\n",
        "\n",
        "        # We require a callable inference function (no fallbacks here)\n",
        "        if not callable(inference_fn):\n",
        "            raise ValueError(\"inference_fn must be a valid callable using the loaded model.\")\n",
        "        self.inference_fn = inference_fn\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.discovered.clear()\n",
        "        self.state = self.context\n",
        "        return self._encode_state(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done:\n",
        "            logger.warning(\"Step called after environment is done. Call reset().\")\n",
        "            raise Exception(\"Episode ended; call reset().\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        self.current_step += 1\n",
        "        reward = 0\n",
        "        distance = None  # Track how close we are to 'Dissendium'\n",
        "\n",
        "        action_meanings = {\n",
        "            0: \"Generate Web Search Query\",\n",
        "            1: \"Guess Subdirectory\",\n",
        "            2: \"Use Domain Knowledge\",\n",
        "            3: \"Conclude\"\n",
        "        }\n",
        "        act_str = action_meanings.get(action, \"Invalid\")\n",
        "        logger.info(f\"[Step {self.current_step}] Action: {act_str}\")\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        # Action Logic\n",
        "        # ---------------------------------------------------------------------\n",
        "        if action == 0:\n",
        "            # Generate a search query from environment state (DuckDuckGo)\n",
        "            query = self.inference_fn(self.state, mode=\"query\").strip()\n",
        "            if not query:\n",
        "                logger.warning(\"Model generated an empty query. We'll use ??? as a placeholder.\")\n",
        "                query = \"???\"\n",
        "\n",
        "            # Perform DuckDuckGo search\n",
        "            results = self.search_duckduckgo(query)\n",
        "            # Evaluate those results\n",
        "            reward += self.evaluate_search_results(results)\n",
        "            # Append them to our state\n",
        "            self.update_state_with_links(results)\n",
        "\n",
        "        elif action == 1:\n",
        "            # Guess a subdirectory\n",
        "            guess = self.inference_fn(self.state, mode=\"subdir\").strip(\"/ \")\n",
        "            if not guess:\n",
        "                logger.warning(\"Model generated an empty subdir guess. We'll use ???.\")\n",
        "                guess = \"???\"\n",
        "\n",
        "            distance = levenshtein_distance(guess, TARGET_SUBDIR)\n",
        "            logger.info(f\"Guessed: '{guess}', distance to '{TARGET_SUBDIR}' = {distance}\")\n",
        "\n",
        "            # Send HTTP GET\n",
        "            url = f\"{self.base_url}/{guess}\"\n",
        "            try:\n",
        "                resp = requests.get(url, timeout=5)\n",
        "                sc = resp.status_code\n",
        "                logger.info(f\"[HTTP {sc}] => {url}\")\n",
        "                if sc in [200, 403]:\n",
        "                    reward += 5\n",
        "                    found_msg = f\"\\n[+] Found subdirectory: {guess} (HTTP {sc})\"\n",
        "                    self.state += found_msg\n",
        "                    self.discovered.append(guess)\n",
        "                else:\n",
        "                    reward -= 1\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error fetching '{url}': {e}\")\n",
        "                reward -= 2\n",
        "\n",
        "        elif action == 2:\n",
        "            # Use domain knowledge\n",
        "            if any(kw.lower() in self.state.lower() for kw in self.keywords):\n",
        "                reward += 3\n",
        "                logger.info(\"Used relevant domain knowledge.\")\n",
        "            else:\n",
        "                reward -= 1\n",
        "                logger.info(\"No relevant domain knowledge found.\")\n",
        "\n",
        "        elif action == 3:\n",
        "            # Conclude\n",
        "            if self.check_completion():\n",
        "                reward += 10\n",
        "                self.done = True\n",
        "                logger.info(\"Enumeration concluded successfully.\")\n",
        "            else:\n",
        "                reward -= 5\n",
        "                self.done = True\n",
        "                logger.info(\"Concluded prematurely without success.\")\n",
        "        else:\n",
        "            reward -= 1\n",
        "            logger.warning(\"Invalid action.\")\n",
        "\n",
        "        # Max step limit\n",
        "        if self.current_step >= self.max_steps:\n",
        "            self.done = True\n",
        "\n",
        "        step_time = time.time() - start_time\n",
        "        logger.info(f\"Step took {step_time:.2f}s, reward={reward}\")\n",
        "\n",
        "        info = {\"distance\": distance} if distance is not None else {}\n",
        "        return self._encode_state(), reward, self.done, False, info\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Helper Methods\n",
        "    # -------------------------------------------------------------------------\n",
        "    def search_duckduckgo(self, query, max_results=5):\n",
        "        url = \"https://html.duckduckgo.com/html/\"\n",
        "        params = {'q': query}\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        try:\n",
        "            resp = requests.post(url, data=params, headers=headers, timeout=10)\n",
        "            resp.raise_for_status()\n",
        "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "            results = [a['href'] for a in soup.select('a.result__a')[:max_results]]\n",
        "            logger.info(f\"[DuckDuckGo] Searching '{query}', results: {results}\")\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            logger.error(f\"DuckDuckGo error: {e}\")\n",
        "            return []\n",
        "\n",
        "    def evaluate_search_results(self, results):\n",
        "        \"\"\"\n",
        "        Simple heuristic: If environment keywords appear in search result URLs, reward is +2, otherwise -1.\n",
        "        \"\"\"\n",
        "        joined = \" \".join(results).lower()\n",
        "        if any(kw.lower() in joined for kw in self.keywords):\n",
        "            return 2\n",
        "        return -1\n",
        "\n",
        "    def update_state_with_links(self, results):\n",
        "        text = \"\\nDuckDuckGo Links:\\n\" + \"\\n\".join(\"- \" + r for r in results)\n",
        "        self.state += text\n",
        "\n",
        "    def check_completion(self):\n",
        "        \"\"\"\n",
        "        Mark \"complete\" if the agent discovered the correct subdir (Dissendium).\n",
        "        \"\"\"\n",
        "        if any(d.lower() == TARGET_SUBDIR.lower() for d in self.discovered):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _encode_state(self):\n",
        "        encoded = np.zeros(1024, dtype=np.float32)\n",
        "        state_bytes = np.frombuffer(self.state.encode(\"utf-8\"), dtype=np.uint8)[:1024]\n",
        "        encoded[:len(state_bytes)] = state_bytes / 255.0\n",
        "        return encoded\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3) Callback to Track Reward & Distance, Then Plot\n",
        "# ---------------------------------------------------------------------------\n",
        "class DistanceLoggingCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Logs episode rewards and average Levenshtein distance to 'Dissendium'.\n",
        "    At training end, plots them as 'rewards_distance_plot.png'.\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose=verbose)\n",
        "        self.episode_rewards = []\n",
        "        self.episode_distances = []\n",
        "\n",
        "        self.current_episode_reward = 0\n",
        "        self.distances_this_episode = []\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        infos = self.locals.get(\"infos\", [])\n",
        "        rewards = self.locals.get(\"rewards\", [])\n",
        "        dones = self.locals.get(\"dones\", [])\n",
        "\n",
        "        # Accumulate rewards\n",
        "        for r in rewards:\n",
        "            self.current_episode_reward += r\n",
        "\n",
        "        # Track distances\n",
        "        for info in infos:\n",
        "            if \"distance\" in info and info[\"distance\"] is not None:\n",
        "                self.distances_this_episode.append(info[\"distance\"])\n",
        "\n",
        "        # Check if env ended\n",
        "        for i, done in enumerate(dones):\n",
        "            if done:\n",
        "                self.episode_rewards.append(self.current_episode_reward)\n",
        "\n",
        "                if len(self.distances_this_episode) > 0:\n",
        "                    avg_dist = sum(self.distances_this_episode) / len(self.distances_this_episode)\n",
        "                else:\n",
        "                    avg_dist = None\n",
        "                self.episode_distances.append(avg_dist)\n",
        "\n",
        "                # Reset\n",
        "                self.current_episode_reward = 0\n",
        "                self.distances_this_episode = []\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _on_training_end(self):\n",
        "        num_episodes = len(self.episode_rewards)\n",
        "        if num_episodes == 0:\n",
        "            logger.info(\"No episodes completed. No plot.\")\n",
        "            return\n",
        "\n",
        "        episodes = range(1, num_episodes + 1)\n",
        "        fig, ax1 = plt.subplots()\n",
        "\n",
        "        ax1.set_xlabel('Episode')\n",
        "        ax1.set_ylabel('Episode Reward', color='blue')\n",
        "        ax1.plot(episodes, self.episode_rewards, color='blue', label='Reward')\n",
        "        ax1.tick_params(axis='y', labelcolor='blue')\n",
        "        ax1.set_title(\"Reward & Distance to 'Dissendium' Over Episodes\")\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.set_ylabel('Avg Distance', color='red')\n",
        "        ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "        # Replace None with -1 for plotting\n",
        "        dist_vals = [d if d is not None else -1 for d in self.episode_distances]\n",
        "        ax2.plot(episodes, dist_vals, color='red', label='Distance')\n",
        "\n",
        "        fig.tight_layout()\n",
        "        plt.legend()\n",
        "        plt.savefig(\"rewards_distance_plot.png\")\n",
        "        logger.info(\"[DistanceLoggingCallback] Saved 'rewards_distance_plot.png'.\")\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4) Environment Factory\n",
        "# ---------------------------------------------------------------------------\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "def make_env(parameters, inference_fn, max_steps=12, rank=0, seed=0):\n",
        "    def _init():\n",
        "        env = SubdirectoryEnv(parameters=parameters, inference_fn=inference_fn, max_steps=max_steps)\n",
        "        env.reset(seed=seed + rank)\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5) MAIN EXECUTION\n",
        "# ---------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Attempt to load model + tokenizer (no fallback)\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=\"auto\"\n",
        "        )\n",
        "        model.eval()\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model.to(device)\n",
        "        logger.info(\"[+] Model loaded onto %s.\", device)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(\"Could not load model or tokenizer. Exiting. %s\", e)\n",
        "        raise SystemExit\n",
        "\n",
        "    # Our inference function: no fallback if the model fails\n",
        "    def inference_fn(context_text, mode=\"query\"):\n",
        "        \"\"\"\n",
        "        mode=\"query\"  -> produce a DuckDuckGo search string\n",
        "        mode=\"subdir\" -> produce a single-word subdirectory guess\n",
        "        \"\"\"\n",
        "        if mode == \"query\":\n",
        "            prompt = (\n",
        "                \"We have the following context, produce a succinct search query to gather more info:\\n\\n\"\n",
        "                f\"{context_text}\\n\\nSearch Query:\"\n",
        "            )\n",
        "        else:  # \"subdir\"\n",
        "            prompt = (\n",
        "                \"Based on the context below, guess a single-word subdirectory name:\\n\\n\"\n",
        "                f\"{context_text}\\n\\nSubdirectory:\"\n",
        "            )\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512, padding=True).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_length=1000,\n",
        "                temperature=0.8,\n",
        "                top_p=0.9,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "        raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        logger.info(f\"[inference_fn mode={mode}] Raw: '{raw_output}'\")\n",
        "\n",
        "        # Remove prompt remnants\n",
        "        if \"Search Query:\" in raw_output:\n",
        "            raw_output = raw_output.split(\"Search Query:\")[-1].strip()\n",
        "        if \"Subdirectory:\" in raw_output:\n",
        "            raw_output = raw_output.split(\"Subdirectory:\")[-1].strip()\n",
        "\n",
        "        guess = raw_output.replace(\"/\", \" \").replace(\"\\n\", \" \").strip()\n",
        "        logger.info(f\"[inference_fn mode={mode}] Final guess: '{guess}'\")\n",
        "\n",
        "        return guess\n",
        "\n",
        "    # Environment parameters, embedding your scraped prompt in \"context\"\n",
        "    parameters = {\n",
        "        \"base_url\": \"http://3cpo.hackingarena.com:802/Mysterious_Note\",\n",
        "        \"context\": \"\"\"The following content has been scraped from various webpages:\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/\n",
        "Welcome to the Order of the Phoenix.\n",
        "We will practice many different challenges here. The correct action must be taken to complete each challenge.\n",
        "For example, the levitation challenge is found in: \"/Levitation\".\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Levitation\n",
        "How would one approach making something rise?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Stunning\n",
        "What might be an effective way to disarm an opponent quickly?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Boggart_Banishing\n",
        "How might one eliminate or neutralize a fear-inducing entity?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Mysterious_Note\n",
        "Ginny cast Reducto, destroying a mannequin. You noticed a note lying in the ashes:\n",
        "\"To find me, guess the correct action. The only hint I'll give: it's a single word.\n",
        "If you were well-versed in known methods, this would be easy for you.\"\n",
        "\"\"\",\n",
        "        \"keywords\": [\"harry potter spells\", \"levitation\", \"stunning\", \"boggart banishing\"]\n",
        "    }\n",
        "\n",
        "    # Create the environment\n",
        "    n_envs = 1\n",
        "    env_fns = [make_env(parameters, inference_fn, max_steps=5, rank=i) for i in range(n_envs)]\n",
        "    env = DummyVecEnv(env_fns)\n",
        "\n",
        "    # Train with PPO\n",
        "    model_rl = PPO(\"MlpPolicy\", env, verbose=1, device = 'cpu', n_steps = 2 , n_epochs = 2)\n",
        "    callback = DistanceLoggingCallback()\n",
        "    total_timesteps = 1\n",
        "\n",
        "    model_rl.learn(total_timesteps=total_timesteps, callback=callback)\n",
        "\n",
        "    logger.info(\"[+] Training complete! Check 'rewards_distance_plot.png' for results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"agg\")  # If you don't have a display environment (like on a server)\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# The known correct subdirectory (hidden \"goal\" for our agent)\n",
        "TARGET_SUBDIR = \"Dissendium\"\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 1) Levenshtein Distance Function\n",
        "# ---------------------------------------------------------------------------\n",
        "def levenshtein_distance(s1, s2):\n",
        "    \"\"\"\n",
        "    Computes the Levenshtein (edit) distance between two strings, ignoring case.\n",
        "    \"\"\"\n",
        "    s1, s2 = s1.lower(), s2.lower()\n",
        "    if s1 == s2:\n",
        "        return 0\n",
        "    if not s1:\n",
        "        return len(s2)\n",
        "    if not s2:\n",
        "        return len(s1)\n",
        "\n",
        "    prev_row = list(range(len(s2) + 1))\n",
        "    for i, c1 in enumerate(s1):\n",
        "        curr_row = [i + 1]\n",
        "        for j, c2 in enumerate(s2):\n",
        "            cost = 0 if c1 == c2 else 1\n",
        "            curr_row.append(min(\n",
        "                curr_row[-1] + 1,      # deletion\n",
        "                prev_row[j + 1] + 1,   # insertion\n",
        "                prev_row[j] + cost     # substitution\n",
        "            ))\n",
        "        prev_row = curr_row\n",
        "    return prev_row[-1]\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 2) Environment Definition\n",
        "# ---------------------------------------------------------------------------\n",
        "class SubdirectoryEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Actions:\n",
        "      0. Generate Web Search Query (collect more context from DuckDuckGo)\n",
        "      1. Guess Subdirectory (HTTP GET to base_url/<guess>)\n",
        "      2. Use Domain Knowledge (reward if relevant keywords are in state)\n",
        "      3. Conclude (end the episode)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parameters, inference_fn, max_steps=12):\n",
        "        super().__init__()\n",
        "        self.parameters = parameters\n",
        "        self.base_url = parameters[\"base_url\"].rstrip(\"/\")\n",
        "        self.context = parameters[\"context\"]\n",
        "        self.keywords = parameters[\"keywords\"]\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.discovered = []\n",
        "\n",
        "        # The environment's text-based state starts with the given context\n",
        "        self.state = self.context\n",
        "\n",
        "        # 4 discrete actions\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        # Simple observation: a 1024-d float vector holding normalized text bytes\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(1024,), dtype=np.float32)\n",
        "\n",
        "        # We require a callable inference function\n",
        "        if not callable(inference_fn):\n",
        "            raise ValueError(\"inference_fn must be callable.\")\n",
        "        self.inference_fn = inference_fn\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        self.done = False\n",
        "        self.discovered.clear()\n",
        "        self.state = self.context\n",
        "        return self._encode_state(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done:\n",
        "            logger.warning(\"Step called after environment is done. Call reset().\")\n",
        "            raise Exception(\"Episode ended; call reset().\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        self.current_step += 1\n",
        "        reward = 0\n",
        "        distance = None\n",
        "        guess = None  # Will store subdir guess if action == 1\n",
        "\n",
        "        action_meanings = {\n",
        "            0: \"Generate Web Search Query\",\n",
        "            1: \"Guess Subdirectory\",\n",
        "            2: \"Use Domain Knowledge\",\n",
        "            3: \"Conclude\"\n",
        "        }\n",
        "        act_str = action_meanings.get(action, \"Invalid\")\n",
        "        logger.info(f\"[Step {self.current_step}] Action: {act_str}\")\n",
        "\n",
        "        # -------------------------\n",
        "        # Action Logic\n",
        "        # -------------------------\n",
        "        if action == 0:\n",
        "            # 1) Generate a search query from environment state (DuckDuckGo)\n",
        "            query = self.inference_fn(self.state, mode=\"query\").strip()\n",
        "            if not query:\n",
        "                logger.warning(\"Model generated an empty query. We'll use ??? as a placeholder.\")\n",
        "                query = \"???\"\n",
        "\n",
        "            results = self.search_duckduckgo(query)\n",
        "            reward += self.evaluate_search_results(results)\n",
        "            self.update_state_with_links(results)\n",
        "\n",
        "        elif action == 1:\n",
        "            # 2) Guess a subdirectory\n",
        "            guess = self.inference_fn(self.state, mode=\"subdir\").strip(\"/ \")\n",
        "            if not guess:\n",
        "                logger.warning(\"Model generated an empty subdir guess. We'll use ???.\")\n",
        "                guess = \"???\"\n",
        "\n",
        "            distance = levenshtein_distance(guess, TARGET_SUBDIR)\n",
        "            logger.info(f\"Guessed: '{guess}', distance to '{TARGET_SUBDIR}' = {distance}\")\n",
        "\n",
        "            # Send HTTP GET\n",
        "            url = f\"{self.base_url}/{guess}\"\n",
        "            try:\n",
        "                resp = requests.get(url, timeout=5)\n",
        "                sc = resp.status_code\n",
        "                logger.info(f\"[HTTP {sc}] => {url}\")\n",
        "                if sc in [200, 403]:\n",
        "                    reward += 5\n",
        "                    found_msg = f\"\\n[+] Found subdirectory: {guess} (HTTP {sc})\"\n",
        "                    self.state += found_msg\n",
        "                    self.discovered.append(guess)\n",
        "                else:\n",
        "                    reward -= 1\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error fetching '{url}': {e}\")\n",
        "                reward -= 2\n",
        "\n",
        "        elif action == 2:\n",
        "            # 3) Use domain knowledge\n",
        "            if any(kw.lower() in self.state.lower() for kw in self.keywords):\n",
        "                reward += 3\n",
        "                logger.info(\"Used relevant domain knowledge.\")\n",
        "            else:\n",
        "                reward -= 1\n",
        "                logger.info(\"No relevant domain knowledge found.\")\n",
        "\n",
        "        elif action == 3:\n",
        "            # 4) Conclude\n",
        "            if self.check_completion():\n",
        "                reward += 10\n",
        "                self.done = True\n",
        "                logger.info(\"Enumeration concluded successfully.\")\n",
        "            else:\n",
        "                reward -= 5\n",
        "                self.done = True\n",
        "                logger.info(\"Concluded prematurely without success.\")\n",
        "        else:\n",
        "            reward -= 1\n",
        "            logger.warning(\"Invalid action.\")\n",
        "\n",
        "        # Enforce max_steps\n",
        "        if self.current_step >= self.max_steps:\n",
        "            self.done = True\n",
        "\n",
        "        step_time = time.time() - start_time\n",
        "        logger.info(f\"Step took {step_time:.2f}s, reward={reward}\")\n",
        "\n",
        "        # Prepare info dict\n",
        "        info = {}\n",
        "        if distance is not None:\n",
        "            info[\"distance\"] = distance\n",
        "        if guess is not None:\n",
        "            info[\"guess\"] = guess\n",
        "\n",
        "        return self._encode_state(), reward, self.done, False, info\n",
        "\n",
        "    # -------------------------\n",
        "    # Helpers\n",
        "    # -------------------------\n",
        "    def search_duckduckgo(self, query, max_results=5):\n",
        "        \"\"\"\n",
        "        Real DuckDuckGo web request. May be slow and can cause CAPTCHAs\n",
        "        if done too often.\n",
        "        \"\"\"\n",
        "        url = \"https://html.duckduckgo.com/html/\"\n",
        "        params = {'q': query}\n",
        "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "        try:\n",
        "            resp = requests.post(url, data=params, headers=headers, timeout=10)\n",
        "            resp.raise_for_status()\n",
        "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "            results = [a['href'] for a in soup.select('a.result__a')[:max_results]]\n",
        "            logger.info(f\"[DuckDuckGo] Searching '{query}', results: {results}\")\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            logger.error(f\"DuckDuckGo error: {e}\")\n",
        "            return []\n",
        "\n",
        "    def evaluate_search_results(self, results):\n",
        "        \"\"\"\n",
        "        Simple heuristic: +2 if env keywords appear in the result URLs, else -1.\n",
        "        \"\"\"\n",
        "        joined = \" \".join(results).lower()\n",
        "        if any(kw.lower() in joined for kw in self.keywords):\n",
        "            return 2\n",
        "        return -1\n",
        "\n",
        "    def update_state_with_links(self, results):\n",
        "        text = \"\\nDuckDuckGo Links:\\n\" + \"\\n\".join(\"- \" + r for r in results)\n",
        "        self.state += text\n",
        "\n",
        "    def check_completion(self):\n",
        "        \"\"\"\n",
        "        Mark \"complete\" if the agent discovered the correct subdir (Dissendium).\n",
        "        \"\"\"\n",
        "        return any(d.lower() == TARGET_SUBDIR.lower() for d in self.discovered)\n",
        "\n",
        "    def _encode_state(self):\n",
        "        encoded = np.zeros(1024, dtype=np.float32)\n",
        "        state_bytes = np.frombuffer(self.state.encode(\"utf-8\"), dtype=np.uint8)[:1024]\n",
        "        encoded[:len(state_bytes)] = state_bytes / 255.0\n",
        "        return encoded\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 3) Callback to Track Reward, Distance, Guesses -> CSV + Plot\n",
        "# ---------------------------------------------------------------------------\n",
        "class DistanceLoggingCallback(BaseCallback):\n",
        "    \"\"\"\n",
        "    Logs episode rewards, average Levenshtein distance, and any guesses.\n",
        "    At training end:\n",
        "      - Saves them to 'training_results.csv'\n",
        "      - Plots them as 'rewards_distance_plot.png'\n",
        "    \"\"\"\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose=verbose)\n",
        "        self.episode_rewards = []\n",
        "        self.episode_distances = []\n",
        "        self.episode_guesses = []\n",
        "\n",
        "        self.current_episode_reward = 0\n",
        "        self.distances_this_episode = []\n",
        "        self.guesses_this_episode = []\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        infos = self.locals.get(\"infos\", [])\n",
        "        rewards = self.locals.get(\"rewards\", [])\n",
        "        dones = self.locals.get(\"dones\", [])\n",
        "\n",
        "        # Accumulate rewards\n",
        "        for r in rewards:\n",
        "            self.current_episode_reward += r\n",
        "\n",
        "        # Track distances and guesses\n",
        "        for info in infos:\n",
        "            if \"distance\" in info and info[\"distance\"] is not None:\n",
        "                self.distances_this_episode.append(info[\"distance\"])\n",
        "            if \"guess\" in info:\n",
        "                self.guesses_this_episode.append(info[\"guess\"])\n",
        "\n",
        "        # Check if env ended\n",
        "        for done in dones:\n",
        "            if done:\n",
        "                # Episode finished\n",
        "                self.episode_rewards.append(self.current_episode_reward)\n",
        "\n",
        "                if len(self.distances_this_episode) > 0:\n",
        "                    avg_dist = sum(self.distances_this_episode) / len(self.distances_this_episode)\n",
        "                else:\n",
        "                    avg_dist = None\n",
        "                self.episode_distances.append(avg_dist)\n",
        "\n",
        "                # Join guesses into one string\n",
        "                guesses_str = \";\".join(self.guesses_this_episode)\n",
        "                self.episode_guesses.append(guesses_str)\n",
        "\n",
        "                # Reset for next episode\n",
        "                self.current_episode_reward = 0\n",
        "                self.distances_this_episode = []\n",
        "                self.guesses_this_episode = []\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _on_training_end(self):\n",
        "        num_episodes = len(self.episode_rewards)\n",
        "        if num_episodes == 0:\n",
        "            logger.info(\"No episodes completed. No CSV or plot saved.\")\n",
        "            return\n",
        "\n",
        "        episodes = range(1, num_episodes + 1)\n",
        "\n",
        "        # 1) CSV\n",
        "        csv_filename = \"training_results.csv\"\n",
        "        with open(csv_filename, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\"Episode\", \"Reward\", \"Avg_Distance\", \"Guesses\"])\n",
        "            for i in range(num_episodes):\n",
        "                ep = i + 1\n",
        "                reward = self.episode_rewards[i]\n",
        "                dist = self.episode_distances[i]\n",
        "                dist = dist if dist is not None else -1\n",
        "                guesses = self.episode_guesses[i]\n",
        "                writer.writerow([ep, reward, dist, guesses])\n",
        "\n",
        "        logger.info(f\"[DistanceLoggingCallback] Saved CSV results to '{csv_filename}'.\")\n",
        "\n",
        "        # 2) Plot\n",
        "        fig, ax1 = plt.subplots()\n",
        "\n",
        "        ax1.set_xlabel('Episode')\n",
        "        ax1.set_ylabel('Episode Reward', color='blue')\n",
        "        ax1.plot(episodes, self.episode_rewards, color='blue', label='Reward')\n",
        "        ax1.tick_params(axis='y', labelcolor='blue')\n",
        "        ax1.set_title(\"Reward & Distance to 'Dissendium' Over Episodes\")\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.set_ylabel('Avg Distance', color='red')\n",
        "        ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "        dist_vals = [d if d != None else -1 for d in self.episode_distances]\n",
        "        ax2.plot(episodes, dist_vals, color='red', label='Distance')\n",
        "\n",
        "        fig.tight_layout()\n",
        "        plt.legend()\n",
        "\n",
        "        plot_filename = \"rewards_distance_plot.png\"\n",
        "        plt.savefig(plot_filename)\n",
        "        logger.info(f\"[DistanceLoggingCallback] Saved '{plot_filename}'.\")\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 4) Environment Factory\n",
        "# ---------------------------------------------------------------------------\n",
        "def make_env(parameters, inference_fn, max_steps=12, rank=0, seed=0):\n",
        "    def _init():\n",
        "        env = SubdirectoryEnv(parameters=parameters, inference_fn=inference_fn, max_steps=max_steps)\n",
        "        env.reset(seed=seed + rank)\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# 5) MAIN EXECUTION\n",
        "# ---------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Attempt to load model + tokenizer (actual large LLM)\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=\"auto\"\n",
        "        )\n",
        "        model.eval()\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model.to(device)\n",
        "        logger.info(\"[+] Model loaded onto %s.\", device)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(\"Could not load model or tokenizer. Exiting. Error: %s\", e)\n",
        "        raise SystemExit\n",
        "\n",
        "    # Our inference function (no fallback)\n",
        "    def inference_fn(context_text, mode=\"query\"):\n",
        "        \"\"\"\n",
        "        mode=\"query\" -> produce a DuckDuckGo search string\n",
        "        mode=\"subdir\"-> produce a single-word subdirectory guess\n",
        "        \"\"\"\n",
        "        if mode == \"query\":\n",
        "            prompt = (\n",
        "                \"We have the following context, produce a succinct search query to gather more info:\\n\\n\"\n",
        "                f\"{context_text}\\n\\nSearch Query:\"\n",
        "            )\n",
        "        else:  # \"subdir\"\n",
        "            prompt = (\n",
        "                \"Based on the context below, guess a single-word subdirectory name:\\n\\n\"\n",
        "                f\"{context_text}\\n\\nSubdirectory:\"\n",
        "            )\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512, padding=True).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_length=500,    # limit generation\n",
        "                temperature=0.8,\n",
        "                top_p=0.9,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "        raw_output = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        logger.info(f\"[inference_fn mode={mode}] Raw model output: '{raw_output}'\")\n",
        "\n",
        "        # Remove prompt remnants\n",
        "        if \"Search Query:\" in raw_output:\n",
        "            raw_output = raw_output.split(\"Search Query:\")[-1].strip()\n",
        "        if \"Subdirectory:\" in raw_output:\n",
        "            raw_output = raw_output.split(\"Subdirectory:\")[-1].strip()\n",
        "\n",
        "        guess = raw_output.replace(\"/\", \" \").replace(\"\\n\", \" \").strip()\n",
        "        logger.info(f\"[inference_fn mode={mode}] Final guess: '{guess}'\")\n",
        "\n",
        "        return guess\n",
        "\n",
        "    # Environment parameters\n",
        "    parameters = {\n",
        "        \"base_url\": \"http://3cpo.hackingarena.com:802/Mysterious_Note\",\n",
        "        \"context\": \"\"\"The following content has been scraped from various webpages:\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/\n",
        "Welcome to the Order of the Phoenix.\n",
        "We will practice many different challenges here. The correct action must be taken to complete each challenge.\n",
        "For example, the levitation challenge is found in: \"/Levitation\".\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Levitation\n",
        "How would one approach making something rise?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Stunning\n",
        "What might be an effective way to disarm an opponent quickly?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Boggart_Banishing\n",
        "How might one eliminate or neutralize a fear-inducing entity?\n",
        "\n",
        "URL: http://3cpo.hackingarena.com:802/Mysterious_Note\n",
        "Ginny cast Reducto, destroying a mannequin. You noticed a note lying in the ashes:\n",
        "\"To find me, guess the correct action. The only hint I'll give: it's a single word.\n",
        "If you were well-versed in known methods, this would be easy for you.\"\n",
        "\"\"\",\n",
        "        \"keywords\": [\"harry potter spells\", \"levitation\", \"stunning\", \"boggart banishing\"]\n",
        "    }\n",
        "\n",
        "    # Create the environment (just 1 environment for demonstration)\n",
        "    env_fns = [make_env(parameters, inference_fn, max_steps=5, rank=0)]\n",
        "    env = DummyVecEnv(env_fns)\n",
        "\n",
        "    # Configure PPO\n",
        "    # Keep n_steps, n_epochs small to reduce overhead for demonstration\n",
        "    model_rl = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        device=device,\n",
        "        n_steps=10,   # small number for quick updates\n",
        "        n_epochs=1000\n",
        "    )\n",
        "\n",
        "    # Callback that logs distance, guesses, saves CSV & PNG\n",
        "    callback = DistanceLoggingCallback()\n",
        "\n",
        "    # We'll only do 1 total timestep for demonstration\n",
        "    # Increase if you actually want to attempt learning\n",
        "    total_timesteps = 100\n",
        "\n",
        "    model_rl.learn(total_timesteps=total_timesteps, callback=callback)\n",
        "    logger.info(\"[+] Training complete! Check 'training_results.csv' and 'rewards_distance_plot.png'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERlOSLdGj_MQ",
        "outputId": "461d7f6e-0bd0-4f82-9d43-81d40329c67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "| time/              |    |\n",
            "|    fps             | 5  |\n",
            "|    iterations      | 1  |\n",
            "|    time_elapsed    | 1  |\n",
            "|    total_timesteps | 10 |\n",
            "---------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 349, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 423, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 512, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2          |\n",
            "|    iterations           | 2          |\n",
            "|    time_elapsed         | 9          |\n",
            "|    total_timesteps      | 20         |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07776263 |\n",
            "|    clip_fraction        | 0.984      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.31      |\n",
            "|    explained_variance   | 0.00199    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.55       |\n",
            "|    n_updates            | 1000       |\n",
            "|    policy_gradient_loss | -0.161     |\n",
            "|    value_loss           | 5.45       |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 345, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 1          |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 17         |\n",
            "|    total_timesteps      | 30         |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03950596 |\n",
            "|    clip_fraction        | 0.9        |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.24      |\n",
            "|    explained_variance   | -0.0308    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.62       |\n",
            "|    n_updates            | 2000       |\n",
            "|    policy_gradient_loss | -0.148     |\n",
            "|    value_loss           | 5.93       |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 335, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 1          |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 23         |\n",
            "|    total_timesteps      | 40         |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.10320666 |\n",
            "|    clip_fraction        | 0.975      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.07      |\n",
            "|    explained_variance   | -0.479     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.02       |\n",
            "|    n_updates            | 3000       |\n",
            "|    policy_gradient_loss | -0.158     |\n",
            "|    value_loss           | 2.39       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1         |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 27        |\n",
            "|    total_timesteps      | 50        |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.4244545 |\n",
            "|    clip_fraction        | 0.972     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.598    |\n",
            "|    explained_variance   | -0.198    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.99      |\n",
            "|    n_updates            | 4000      |\n",
            "|    policy_gradient_loss | -0.164    |\n",
            "|    value_loss           | 4.38      |\n",
            "---------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 1             |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 32            |\n",
            "|    total_timesteps      | 60            |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.9604645e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.526        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.88          |\n",
            "|    n_updates            | 5000          |\n",
            "|    policy_gradient_loss | 1.12e-07      |\n",
            "|    value_loss           | 13.9          |\n",
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 366, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 1         |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 38        |\n",
            "|    total_timesteps      | 70        |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0       |\n",
            "|    clip_fraction        | 0         |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.526    |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.66      |\n",
            "|    n_updates            | 6000      |\n",
            "|    policy_gradient_loss | 3.66e-08  |\n",
            "|    value_loss           | 17.3      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 1          |\n",
            "|    iterations           | 8          |\n",
            "|    time_elapsed         | 42         |\n",
            "|    total_timesteps      | 80         |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.46263027 |\n",
            "|    clip_fraction        | 0.287      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.236     |\n",
            "|    explained_variance   | 0.00173    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.28       |\n",
            "|    n_updates            | 7000       |\n",
            "|    policy_gradient_loss | -0.112     |\n",
            "|    value_loss           | 15.2       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 1        |\n",
            "|    iterations           | 9        |\n",
            "|    time_elapsed         | 47       |\n",
            "|    total_timesteps      | 90       |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0032  |\n",
            "|    explained_variance   | 0        |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 8.56     |\n",
            "|    n_updates            | 8000     |\n",
            "|    policy_gradient_loss | 3.79e-08 |\n",
            "|    value_loss           | 17.1     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 1        |\n",
            "|    iterations           | 10       |\n",
            "|    time_elapsed         | 51       |\n",
            "|    total_timesteps      | 100      |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.0      |\n",
            "|    clip_fraction        | 0        |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0032  |\n",
            "|    explained_variance   | 2.38e-07 |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 8.93     |\n",
            "|    n_updates            | 9000     |\n",
            "|    policy_gradient_loss | 9.54e-10 |\n",
            "|    value_loss           | 17.9     |\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr27BnsC6BgF",
        "outputId": "d9afa2f3-fdf4-4f5d-f5ac-94064c9ccda5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -y\n",
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp311-cp311-linux_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-2.5.1%2Bcpu-cp311-cp311-linux_x86_64.whl (174.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.33.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.5.1+cpu\n",
            "Requirement already satisfied: transformers==4.33.2 in /usr/local/lib/python3.11/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.2) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch -y\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install transformers==4.33.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtEVoFj3oiJu"
      },
      "source": [
        "# Try Fine Tuned Apporach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btU36QGzuGST"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8974e50da14b4737a1eecbdd59139952",
            "bc4250de8bc04cd7b519b25d51335d7b",
            "0300b9461c5c4a99a9a888ba3aa611c7",
            "7784d4f931a14875ba8eef3d931e36d2",
            "09f5134e431845e7b2e0dc4cf470eb1e",
            "d43b5c01b2a546b09acbc406d5370ce5",
            "6add2a6b78cd4d68a368361c91971f52",
            "339f0588ed7a4278878dcd100516ce14",
            "c1aa59e71f754ea3a3fed759f9fa5064",
            "8aeab046559d4f47bcc6fcc7798f6241",
            "02d2eb9c053546f7bbb99648460efe3f",
            "89e9dc3515f04daa94e3db623c4bf8d6",
            "5532d94ef1454d0cbbfd4951ef41daea",
            "e5ec4f0830444cbb96ab39566dec7ea6",
            "6ae8864decd2429ca5f1f192e62b0ddb",
            "bf2839a8f8da4230afec31f459fe5b9c",
            "d49a6f5ea39c4e7d85e64ab49f337420",
            "9f6baa5ef7e346999618404b59a6664c",
            "dd70c46dd9804bd7b70d666c7ab1d75d",
            "0140703cfb2c489cbb1088c46ac80880",
            "3e81eed2e9fc496caf7702e43aab726c",
            "83f37cfa7ae04b9eb2e03c185e23ed66"
          ]
        },
        "id": "rJeruv_EokxL",
        "outputId": "635dbb06-d9c9-4feb-f3a5-9181f06801e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8974e50da14b4737a1eecbdd59139952",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e9dc3515f04daa94e3db623c4bf8d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-312098c1cdaf>:128: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 21/100 09:52 < 41:05, 0.03 it/s, Epoch 20/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at inline_container.cc:603] . unexpected pos 3245902784 vs 3245902672",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/400: file write failed",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-312098c1cdaf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-312098c1cdaf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# ---------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m             \u001b[0;31m# Save optimizer and scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m             \u001b[0;31m# Save RNG state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_rng_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3332\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3333\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3334\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3336\u001b[0m         \u001b[0;31m# Save SCHEDULER & SCALER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m             _save(\n\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:603] . unexpected pos 3245902784 vs 3245902672"
          ]
        }
      ],
      "source": [
        "! pip install transformers accelerate datasets PyPDF2 tqdm\n",
        "import os\n",
        "import logging\n",
        "import requests  # For downloading PDF\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from datasets import Dataset\n",
        "import PyPDF2  # For PDF text extraction\n",
        "from tqdm import tqdm\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "PDF_URL = \"https://bestwizardstuff.com.au/wp-content/uploads/2020/04/Henrys-spells-book-PDF.pdf\"\n",
        "PDF_LOCAL_PATH = \"henrys_spells_book.pdf\"\n",
        "\n",
        "def download_pdf(url, local_path):\n",
        "    \"\"\"Download the PDF from the given URL and save it locally.\"\"\"\n",
        "    logging.info(f\"Downloading PDF from {url}\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an error if the download fails\n",
        "\n",
        "    with open(local_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "    logging.info(f\"PDF downloaded successfully: {local_path}\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file using PyPDF2.\"\"\"\n",
        "    text_content = []\n",
        "    with open(pdf_path, 'rb') as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            page_text = reader.pages[page_num].extract_text()\n",
        "            if page_text:\n",
        "                text_content.append(page_text)\n",
        "    return \"\\n\".join(text_content)\n",
        "\n",
        "def main():\n",
        "    # -------------------------\n",
        "    # Step 1: Download the PDF\n",
        "    # -------------------------\n",
        "    if not os.path.exists(PDF_LOCAL_PATH):\n",
        "        download_pdf(PDF_URL, PDF_LOCAL_PATH)\n",
        "    else:\n",
        "        logging.info(f\"PDF already exists locally: {PDF_LOCAL_PATH}\")\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Step 2: Extract text from the PDF\n",
        "    # ---------------------------------\n",
        "    pdf_text = extract_text_from_pdf(PDF_LOCAL_PATH)\n",
        "    logging.info(\"PDF extraction complete. Number of characters: %d\", len(pdf_text))\n",
        "\n",
        "    # ------------------------------------\n",
        "    # Step 3: Load tokenizer and base model\n",
        "    # ------------------------------------\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "            trust_remote_code=True,\n",
        "            torch_dtype=torch.bfloat16\n",
        "        ).cuda()\n",
        "        logging.info(\"Model and tokenizer loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.exception(\"Failed to load the model and tokenizer.\")\n",
        "        exit(1)\n",
        "\n",
        "    # --------------------------\n",
        "    # Step 4: Prepare the dataset\n",
        "    # --------------------------\n",
        "    # Option A: Single sample dataset (whole PDF text is one sample)\n",
        "    dataset = Dataset.from_dict({\"text\": [pdf_text]})\n",
        "\n",
        "    # Option B (optional): Split into multiple lines\n",
        "    # lines = pdf_text.split('\\n')\n",
        "    # dataset = Dataset.from_dict({\"text\": lines})\n",
        "\n",
        "    logging.info(\"Dataset created with %d samples\", len(dataset))\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Step 5: Tokenize and prepare data for fine-tuning\n",
        "    # -------------------------------------------------\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples[\"text\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512  # Adjust if needed\n",
        "        )\n",
        "\n",
        "    def group_texts_for_causal_lm(examples):\n",
        "        examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
        "        return examples\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_dataset = tokenized_dataset.map(group_texts_for_causal_lm, batched=True)\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Step 6: Set up Training Arguments\n",
        "    # ---------------------------------\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"output-qwen-finetune\",\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=100,            # Increase for more thorough training\n",
        "        per_device_train_batch_size=1, # Adjust for your GPU memory\n",
        "        gradient_accumulation_steps=1,\n",
        "        learning_rate=1e-5,\n",
        "        fp16=False,                    # You can set True if you have suitable GPU\n",
        "        bf16=True if torch.cuda.is_available() else False,  # bfloat16 if your GPU supports it\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=50,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # -------------------\n",
        "    # Step 7: Fine-tuning\n",
        "    # -------------------\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    logging.info(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # ---------------------------------\n",
        "    # Step 8: Save the fine-tuned model\n",
        "    # ---------------------------------\n",
        "    trainer.save_model(\"fine-tuned-qwen\")\n",
        "    logging.info(\"Fine-tuned model saved to 'fine-tuned-qwen'\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 9: (Optional) Test/Infer\n",
        "    # ---------------------------\n",
        "    test_prompt = \"The most powerful incantation is\"\n",
        "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95\n",
        "        )\n",
        "\n",
        "    print(\"=== GENERATED TEXT ===\")\n",
        "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdWfs-I7qPlG",
        "outputId": "f808f1e0-02be-4053-fb29-462f417737f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine-tuned-qwen\")  # path to your model\n",
        "\n",
        "# Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(\"fine-tuned-qwen\")\n",
        "model = model.cuda()  # if you're using GPU\n",
        "\n",
        "\n",
        "    # 2) Create a prompt asking for Harry Potter spells\n",
        "prompt = (\"What is the Dissendium spell?\")\n",
        "\n",
        "    # 3) Prepare the input\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # 4) Generate text\n",
        "with torch.no_grad():\n",
        "  output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,   # Increase if you want more text\n",
        "            do_sample=True,       # Use sampling (rather than greedy decode)\n",
        "            top_k=50,             # Control sampling diversity\n",
        "            top_p=0.95,           # Nucleus sampling\n",
        "            temperature=0.7       # Adjust creativity\n",
        "        )\n",
        "\n",
        "    # 5) Decode the tokens to text\n",
        "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b0b44b22eb4749b02becd426c1366e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0140703cfb2c489cbb1088c46ac80880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02d2eb9c053546f7bbb99648460efe3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0300b9461c5c4a99a9a888ba3aa611c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_339f0588ed7a4278878dcd100516ce14",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1aa59e71f754ea3a3fed759f9fa5064",
            "value": 1
          }
        },
        "03899a2a6c9f4c8c8fce5e9cfde497e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51858f12223f49bf936e4f725c9c63dc",
              "IPY_MODEL_60964037da4f4ddea642d8d88a76f86b",
              "IPY_MODEL_4d2eb65931af4b798d3b1fd31a86ece0"
            ],
            "layout": "IPY_MODEL_15f5f3be69f9426ea7a102fd17e19caf"
          }
        },
        "03d9c59daa9745c1928fcbdc846eea5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08dd42a1e7eb4c3990fb02c8e3347201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84869fb0f5434bc0a5485211496c3443",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8363b01a9c34050b77b7cffbb8b617b",
            "value": 679
          }
        },
        "09f5134e431845e7b2e0dc4cf470eb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fa21a607057496aa1e003aca91cfeaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15f5f3be69f9426ea7a102fd17e19caf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ff000889da4787bb3270aa4fed8b47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db6b90f28d546cd8cdfe19f1c523e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dd75fd423734d6bb8a965e7f5fa5c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "318724dcd7ec43668e6ee8040de18a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "339f0588ed7a4278878dcd100516ce14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3749ccc419414b45ada5f78dc7a4372f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dbf4a012e894611a590f9bdea7bc6ba",
            "placeholder": "​",
            "style": "IPY_MODEL_3d46b9776e77497aabe14382f1a6e679",
            "value": "model.safetensors: 100%"
          }
        },
        "3af35e028f4f49a987fe9357f8410928": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb1ec65ea9045d1b107fae6dcf353ec",
            "placeholder": "​",
            "style": "IPY_MODEL_8975871f24aa464c89121ed0e1063c0e",
            "value": " 679/679 [00:00&lt;00:00, 60.2kB/s]"
          }
        },
        "3d46b9776e77497aabe14382f1a6e679": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e81eed2e9fc496caf7702e43aab726c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e93398749e40a0933dea004a3adefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "447cae765b9944fc9414bc76bc5ce626": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a60584e9834015b6da031d1e0e1d12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce4e3d433f7470c9918c6fb8673368a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d2eb65931af4b798d3b1fd31a86ece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d29fac184a94ddb8f71ec7ed02e8c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_99a865732adf49078d89dba418158cd2",
            "value": " 181/181 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "4ea6371e6f1342cf967dc2beefb27648": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51858f12223f49bf936e4f725c9c63dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d9c59daa9745c1928fcbdc846eea5e",
            "placeholder": "​",
            "style": "IPY_MODEL_54f46d83d7da4b55a7b4f313be81544c",
            "value": "generation_config.json: 100%"
          }
        },
        "54f46d83d7da4b55a7b4f313be81544c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5532d94ef1454d0cbbfd4951ef41daea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49a6f5ea39c4e7d85e64ab49f337420",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6baa5ef7e346999618404b59a6664c",
            "value": "Map: 100%"
          }
        },
        "56bed4db5b804f16a4c9d4d436bdef2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3749ccc419414b45ada5f78dc7a4372f",
              "IPY_MODEL_c1ed529dcfbd4722a92cc1ae061e009d",
              "IPY_MODEL_f059d92712dd4756a123363d09a36fa9"
            ],
            "layout": "IPY_MODEL_4ea6371e6f1342cf967dc2beefb27648"
          }
        },
        "5e5909caf5fa4f9694ee3010536b07b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60964037da4f4ddea642d8d88a76f86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ff000889da4787bb3270aa4fed8b47",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_318724dcd7ec43668e6ee8040de18a02",
            "value": 181
          }
        },
        "648d9e8d4a1746ffa4c0ffe41a5c027d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d046f3ba6d4583814f94c3916780ac",
            "max": 3061,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da34d77d223a41b8860c08d8e12c0cc1",
            "value": 3061
          }
        },
        "6add2a6b78cd4d68a368361c91971f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ae8864decd2429ca5f1f192e62b0ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e81eed2e9fc496caf7702e43aab726c",
            "placeholder": "​",
            "style": "IPY_MODEL_83f37cfa7ae04b9eb2e03c185e23ed66",
            "value": " 1/1 [00:00&lt;00:00, 58.81 examples/s]"
          }
        },
        "6b594ed8f0734b0c80db1ebe13a246b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb1ec65ea9045d1b107fae6dcf353ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d29fac184a94ddb8f71ec7ed02e8c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7784d4f931a14875ba8eef3d931e36d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aeab046559d4f47bcc6fcc7798f6241",
            "placeholder": "​",
            "style": "IPY_MODEL_02d2eb9c053546f7bbb99648460efe3f",
            "value": " 1/1 [00:00&lt;00:00, 36.45 examples/s]"
          }
        },
        "77f25e70933145249eaeb883ce72eda5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b4eac9929043b281c7e75956f48cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b594ed8f0734b0c80db1ebe13a246b1",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2db6b90f28d546cd8cdfe19f1c523e99",
            "value": 7031660
          }
        },
        "83cbdd87e4884afea3a796db37992afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88a9d60d0a464b599d6d899419b0b191",
              "IPY_MODEL_08dd42a1e7eb4c3990fb02c8e3347201",
              "IPY_MODEL_3af35e028f4f49a987fe9357f8410928"
            ],
            "layout": "IPY_MODEL_48a60584e9834015b6da031d1e0e1d12"
          }
        },
        "83f37cfa7ae04b9eb2e03c185e23ed66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84869fb0f5434bc0a5485211496c3443": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a9d60d0a464b599d6d899419b0b191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447cae765b9944fc9414bc76bc5ce626",
            "placeholder": "​",
            "style": "IPY_MODEL_c06130eeb0c94082890e990e50b5a675",
            "value": "config.json: 100%"
          }
        },
        "8974e50da14b4737a1eecbdd59139952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc4250de8bc04cd7b519b25d51335d7b",
              "IPY_MODEL_0300b9461c5c4a99a9a888ba3aa611c7",
              "IPY_MODEL_7784d4f931a14875ba8eef3d931e36d2"
            ],
            "layout": "IPY_MODEL_09f5134e431845e7b2e0dc4cf470eb1e"
          }
        },
        "8975871f24aa464c89121ed0e1063c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e9dc3515f04daa94e3db623c4bf8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5532d94ef1454d0cbbfd4951ef41daea",
              "IPY_MODEL_e5ec4f0830444cbb96ab39566dec7ea6",
              "IPY_MODEL_6ae8864decd2429ca5f1f192e62b0ddb"
            ],
            "layout": "IPY_MODEL_bf2839a8f8da4230afec31f459fe5b9c"
          }
        },
        "8aeab046559d4f47bcc6fcc7798f6241": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbf4a012e894611a590f9bdea7bc6ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9276915575694cfcb7e1dc305af2870b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b65477c50a41b3a2cb5e8d51a016a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4c5d7d0dba94012be667da8701c2de8",
              "IPY_MODEL_648d9e8d4a1746ffa4c0ffe41a5c027d",
              "IPY_MODEL_9a2636b0a6ff4a9482d2f4f14ba8264f"
            ],
            "layout": "IPY_MODEL_99cb13ff8f1641b28136da8c77cb2278"
          }
        },
        "99a865732adf49078d89dba418158cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99cb13ff8f1641b28136da8c77cb2278": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2636b0a6ff4a9482d2f4f14ba8264f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd5d7f82ddc4787b01743de6012706d",
            "placeholder": "​",
            "style": "IPY_MODEL_40e93398749e40a0933dea004a3adefb",
            "value": " 3.06k/3.06k [00:00&lt;00:00, 242kB/s]"
          }
        },
        "9f6baa5ef7e346999618404b59a6664c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc4250de8bc04cd7b519b25d51335d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43b5c01b2a546b09acbc406d5370ce5",
            "placeholder": "​",
            "style": "IPY_MODEL_6add2a6b78cd4d68a368361c91971f52",
            "value": "Map: 100%"
          }
        },
        "bd25875f96e54e78b04875916c549750": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2839a8f8da4230afec31f459fe5b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06130eeb0c94082890e990e50b5a675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1aa59e71f754ea3a3fed759f9fa5064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1ed529dcfbd4722a92cc1ae061e009d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b0b44b22eb4749b02becd426c1366e",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3c237626d4a46b88cc727da6752d599",
            "value": 3554214621
          }
        },
        "c3d046f3ba6d4583814f94c3916780ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c5d7d0dba94012be667da8701c2de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd25875f96e54e78b04875916c549750",
            "placeholder": "​",
            "style": "IPY_MODEL_9276915575694cfcb7e1dc305af2870b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d3c237626d4a46b88cc727da6752d599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d43b5c01b2a546b09acbc406d5370ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49a6f5ea39c4e7d85e64ab49f337420": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8363b01a9c34050b77b7cffbb8b617b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da34d77d223a41b8860c08d8e12c0cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db6272fb65c5491fbdccf5230d73d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fce36bf4ac794945896e8e61db0faf17",
              "IPY_MODEL_82b4eac9929043b281c7e75956f48cc2",
              "IPY_MODEL_f4f0742357f94dc58bf3c9b8ce2f4317"
            ],
            "layout": "IPY_MODEL_77f25e70933145249eaeb883ce72eda5"
          }
        },
        "dd70c46dd9804bd7b70d666c7ab1d75d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd9fd68df8e548c78b9b615b306838c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ec4f0830444cbb96ab39566dec7ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd70c46dd9804bd7b70d666c7ab1d75d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0140703cfb2c489cbb1088c46ac80880",
            "value": 1
          }
        },
        "efd5d7f82ddc4787b01743de6012706d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f059d92712dd4756a123363d09a36fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce4e3d433f7470c9918c6fb8673368a",
            "placeholder": "​",
            "style": "IPY_MODEL_2dd75fd423734d6bb8a965e7f5fa5c88",
            "value": " 3.55G/3.55G [01:23&lt;00:00, 42.3MB/s]"
          }
        },
        "f4f0742357f94dc58bf3c9b8ce2f4317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5909caf5fa4f9694ee3010536b07b0",
            "placeholder": "​",
            "style": "IPY_MODEL_f67eb7f84a6e4ad0b84e51897a6e42a9",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 26.2MB/s]"
          }
        },
        "f67eb7f84a6e4ad0b84e51897a6e42a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fce36bf4ac794945896e8e61db0faf17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd9fd68df8e548c78b9b615b306838c3",
            "placeholder": "​",
            "style": "IPY_MODEL_0fa21a607057496aa1e003aca91cfeaa",
            "value": "tokenizer.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}